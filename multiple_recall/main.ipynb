{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 14:48:19.161689: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 导包\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from tqdm import tqdm  \n",
    "from collections import defaultdict  \n",
    "import os, math, warnings, math, pickle\n",
    "from tqdm import tqdm\n",
    "import faiss\n",
    "import collections\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "# from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from deepmatch.models import *\n",
    "from deepmatch.utils import sampledsoftmaxloss\n",
    "from model import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data_path/'\n",
    "save_path = '../tmp_results/'\n",
    "# 做召回评估的一个标志, 如果不进行评估就是直接使用全量数据进行召回\n",
    "metric_recall = True\n",
    "user_multi_recall_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采样数据\n",
    "# all_click_df = get_all_click_sample(data_path)\n",
    "\n",
    "# 全量训练集\n",
    "all_click_df = get_all_click_df(data_path,offline=False)\n",
    "max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "# 对时间戳进行归一化,用于在关联规则的时候计算权重\n",
    "all_click_df['click_timestamp'] = all_click_df[['click_timestamp']].apply(max_min_scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item 信息\n",
    "item_info_df = get_item_info_df(data_path)\n",
    "item_emb_dict = get_item_emb_dict(data_path,save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于这里需要做召回评估，所以讲训练集中的最后一次点击都提取了出来\n",
    "if metric_recall:\n",
    "    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [00:14<00:00, 16677.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4208/4208 [==============================] - 310s 73ms/step - loss: 2.3637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250000it [00:16, 15191.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndef get_item_embedding_v2(item_embedding, item_input_layer):\\n    item_out = tf.gather(item_embedding, item_input_layer)\\n    return Lambda(lambda x: tf.squeeze(x, 1))(item_out)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# youtubudnn召回\n",
    "user_multi_recall_dict['youtubednn_recall'] = youtubednn_u2i_dict(trn_hist_click_df,save_path, topk=20)\n",
    "\n",
    "#如果报get_item_embedding的错 因为tensorflow版本不兼容的问题  将原来的get_item_embedding拆开就可以了\n",
    "\"\"\"\n",
    "def get_item_embedding_v2(item_embedding, item_input_layer):\n",
    "    item_out = tf.gather(item_embedding, item_input_layer)\n",
    "    return Lambda(lambda x: tf.squeeze(x, 1))(item_out)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " topk:  10  :  hit_num:  87 hit_rate:  0.00035 user_num :  250000\n",
      " topk:  20  :  hit_num:  158 hit_rate:  0.00063 user_num :  250000\n"
     ]
    }
   ],
   "source": [
    "### 命中率极低\n",
    "metrics_recall(user_multi_recall_dict['youtubednn_recall'], trn_last_click_df, topk=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [04:27<00:00, 932.97it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/liuyangdong/Documents/天池/news_rec/multiple_recall/main.ipynb 单元格 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liuyangdong/Documents/%E5%A4%A9%E6%B1%A0/news_rec/multiple_recall/main.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m item_emb_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(data_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/articles_emb.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/liuyangdong/Documents/%E5%A4%A9%E6%B1%A0/news_rec/multiple_recall/main.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# 对于每一篇文章， 基于embedding的相似性返回topk个与其最相似的文章\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/liuyangdong/Documents/%E5%A4%A9%E6%B1%A0/news_rec/multiple_recall/main.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m emb_i2i_sim \u001b[39m=\u001b[39m embdding_sim(all_click_df, item_emb_df, save_path, topk\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m) \u001b[39m# topk可以自行设置\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/liuyangdong/Documents/%E5%A4%A9%E6%B1%A0/news_rec/multiple_recall/main.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# i2i_sim = pickle.load(open(save_path + 'itemcf_i2i_sim.pkl', 'rb'))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/liuyangdong/Documents/%E5%A4%A9%E6%B1%A0/news_rec/multiple_recall/main.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# emb_i2i_sim = pickle.load(open(save_path + 'emb_i2i_sim.pkl', 'rb'))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/liuyangdong/Documents/%E5%A4%A9%E6%B1%A0/news_rec/multiple_recall/main.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m sim_item_topk \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n",
      "File \u001b[0;32m~/Documents/天池/news_rec/multiple_recall/../utils.py:250\u001b[0m, in \u001b[0;36membdding_sim\u001b[0;34m(click_df, item_emb_df, save_path, topk)\u001b[0m\n\u001b[1;32m    248\u001b[0m item_index\u001b[39m.\u001b[39madd(item_emb_np)\n\u001b[1;32m    249\u001b[0m \u001b[39m# 相似度查询，给每个索引位置上的向量返回topk个item以及相似度\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m sim, idx \u001b[39m=\u001b[39m item_index\u001b[39m.\u001b[39;49msearch(item_emb_np, topk) \u001b[39m# 返回的是列表\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39m# 将向量检索的结果保存成原始id的对应关系\u001b[39;00m\n\u001b[1;32m    253\u001b[0m item_sim_dict \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mdefaultdict(\u001b[39mdict\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/faiss/class_wrappers.py:343\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_search\u001b[0;34m(self, x, k, params, D, I)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    341\u001b[0m     \u001b[39massert\u001b[39;00m I\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (n, k)\n\u001b[0;32m--> 343\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearch_c(n, swig_ptr(x), k, swig_ptr(D), swig_ptr(I), params)\n\u001b[1;32m    344\u001b[0m \u001b[39mreturn\u001b[39;00m D, I\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/faiss/swigfaiss_avx2.py:1989\u001b[0m, in \u001b[0;36mIndexFlat.search\u001b[0;34m(self, n, x, k, distances, labels, params)\u001b[0m\n\u001b[1;32m   1988\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearch\u001b[39m(\u001b[39mself\u001b[39m, n, x, k, distances, labels, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1989\u001b[0m     \u001b[39mreturn\u001b[39;00m _swigfaiss_avx2\u001b[39m.\u001b[39;49mIndexFlat_search(\u001b[39mself\u001b[39;49m, n, x, k, distances, labels, params)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# icf recall\n",
    "item_type_dict, item_words_dict, item_created_time_dict = get_item_info_dict(item_info_df)\n",
    "\n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "user_item_time_dict = get_user_item_time(trn_hist_click_df)\n",
    "\n",
    "# 文章与文章的相似性矩阵\n",
    "i2i_sim = itemcf_sim(all_click_df, item_created_time_dict,save_path=save_path)\n",
    "item_emb_df = pd.read_csv(data_path + '/articles_emb.csv')\n",
    "# 对于每一篇文章， 基于embedding的相似性返回topk个与其最相似的文章\n",
    "emb_i2i_sim = embdding_sim(all_click_df, item_emb_df, save_path, topk=10) # topk可以自行设置\n",
    "\n",
    "\n",
    "\n",
    "# i2i_sim = pickle.load(open(save_path + 'itemcf_i2i_sim.pkl', 'rb'))\n",
    "# emb_i2i_sim = pickle.load(open(save_path + 'emb_i2i_sim.pkl', 'rb'))\n",
    "\n",
    "sim_item_topk = 20\n",
    "recall_item_num = 10\n",
    "item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)\n",
    "\n",
    "for user in tqdm(trn_hist_click_df['user_id'].unique()):\n",
    "    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, \\\n",
    "                                                        i2i_sim, sim_item_topk, recall_item_num, \\\n",
    "                                                        item_topk_click, item_created_time_dict, emb_i2i_sim)\n",
    "\n",
    "user_multi_recall_dict['itemcf_sim_itemcf_recall'] = user_recall_items_dict\n",
    "pickle.dump(user_multi_recall_dict['itemcf_sim_itemcf_recall'], open(save_path + 'itemcf_recall_dict.pkl', 'wb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
